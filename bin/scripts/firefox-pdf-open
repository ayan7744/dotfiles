#!/bin/bash

# --- Clipboard Handling ---

# 1. Save the original clipboard content at the very beginning.
original_clipboard=$(xclip -o -selection clipboard 2>/dev/null)


# --- Firefox URL Extraction ---

window_id=$(xdotool search --onlyvisible --class "firefox" | head -1)

if [[ -z "$window_id" ]]; then
    exit 1
fi

# Activate the window, simulate keystrokes to copy the URL
xdotool windowactivate "$window_id"
xdotool key --clearmodifiers "ctrl+l"
xdotool key --clearmodifiers "ctrl+c"
sleep 0.1 # Give a moment for the clipboard to update

# 2. Read the new URL from the clipboard into a variable.
url_from_firefox=$(xclip -o -selection clipboard)

# 3. IMMEDIATELY restore the original clipboard content.
#    From this point on, the live clipboard is back to its original state.
echo -n "$original_clipboard" | xclip -i -selection clipboard


# --- URL Processing and Download ---
#    The rest of the script now uses the 'url_from_firefox' variable,
#    not the live clipboard.

if [[ -z "$url_from_firefox" ]]; then
    exit 1
fi

# First, handle the moz-extension wrapper to get the real URL.
if [[ "$url_from_firefox" == *"moz-extension://"* && "$url_from_firefox" == *"?target="* ]]; then
    url=$(echo "$url_from_firefox" | sed -n 's/.*target=\(.*\)/\1/p')
else
    url="$url_from_firefox"
fi

# Next, check if the URL is an arXiv abstract page and transform it to the PDF link.
if [[ "$url" == *"arxiv.org/abs/"* ]]; then
    download_url=${url//\/abs\//\/pdf\/}
else
    download_url="$url"
fi

tmp_file=$(mktemp /tmp/clipboard_pdf_XXXXXX.pdf)

# 4. The trap now ONLY handles file cleanup. Clipboard is already restored.
trap 'rm -f "$tmp_file"' EXIT

if ! curl -L -sS -o "$tmp_file" "$download_url"; then
    exit 1
fi

if ! file --mime-type -b "$tmp_file" | grep -q "application/pdf"; then
    exit 1
fi

# 5. Open Zathura. The original clipboard is available for use.
zathura "$tmp_file"
